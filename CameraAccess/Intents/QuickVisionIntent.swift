/*
 * Quick Vision Intent
 * App Intent - æ”¯æŒ Siri å’Œå¿«æ·æŒ‡ä»¤è§¦å‘å¿«é€Ÿè¯†å›¾
 *
 * ä½¿ç”¨æ–¹å¼ï¼š
 * 1. Siri: "å˜¿ Siriï¼Œç”¨ TurboMeta è¯†å›¾"
 * 2. å¿«æ·æŒ‡ä»¤ï¼šæ·»åŠ  "TurboMeta å¿«é€Ÿè¯†å›¾" åŠ¨ä½œ
 * 3. é”å±å¿«æ·æ–¹å¼
 */

import AppIntents
import UIKit
import SwiftUI

// MARK: - Quick Vision Intent

@available(iOS 16.0, *)
struct QuickVisionIntent: AppIntent {
    static var title: LocalizedStringResource = "å¿«é€Ÿè¯†å›¾"
    static var description = IntentDescription("ä½¿ç”¨ Ray-Ban Meta çœ¼é•œæ‹ç…§å¹¶è¯†åˆ«å›¾åƒå†…å®¹")

    // å°è¯•åå°è¿è¡Œï¼ˆä½† SDK å¯èƒ½éœ€è¦å‰å°ï¼‰
    // è®¾ä¸º false å¯ä»¥åœ¨é”å±æ—¶å°è¯•æ‰§è¡Œï¼Œä½†è§†é¢‘æµå¯èƒ½å—é™
    static var openAppWhenRun: Bool = false

    // Intent å‚æ•°ï¼ˆå¯é€‰ï¼‰
    @Parameter(title: "è‡ªå®šä¹‰æç¤º")
    var customPrompt: String?

    @MainActor
    func perform() async throws -> some IntentResult & ProvidesDialog {
        print("ğŸš€ [QuickVisionIntent] Intent triggered (background mode)")

        // æ£€æŸ¥ QuickVisionManager æ˜¯å¦å·²åˆå§‹åŒ–
        let manager = QuickVisionManager.shared

        // å¦‚æœ streamViewModel æ²¡æœ‰è®¾ç½®ï¼Œè¯´æ˜ App æœªå®Œå…¨åˆå§‹åŒ–
        // æ­¤æ—¶éœ€è¦æ‰“å¼€ App
        if manager.streamViewModel == nil {
            print("âš ï¸ [QuickVisionIntent] App not initialized, sending notification")
            // å‘é€é€šçŸ¥ï¼Œè®© App æ‰“å¼€å¹¶æ‰§è¡Œå¿«é€Ÿè¯†å›¾
            NotificationCenter.default.post(
                name: .quickVisionTriggered,
                object: nil,
                userInfo: ["customPrompt": customPrompt as Any]
            )
            return .result(dialog: "æ­£åœ¨å¯åŠ¨å¿«é€Ÿè¯†å›¾ï¼Œè¯·ç¨å€™...")
        }

        // App å·²åˆå§‹åŒ–ï¼Œç›´æ¥æ‰§è¡Œ
        print("ğŸš€ [QuickVisionIntent] App initialized, executing directly")
        await manager.performQuickVisionFromIntent(customPrompt: customPrompt)

        if let result = manager.lastResult {
            return .result(dialog: "è¯†åˆ«å®Œæˆï¼š\(result)")
        } else if let error = manager.errorMessage {
            return .result(dialog: "è¯†åˆ«å¤±è´¥ï¼š\(error)")
        } else {
            return .result(dialog: "è¯†åˆ«å®Œæˆ")
        }
    }
}

// MARK: - App Shortcuts Provider

@available(iOS 16.0, *)
struct TurboMetaShortcuts: AppShortcutsProvider {
    static var appShortcuts: [AppShortcut] {
        AppShortcut(
            intent: QuickVisionIntent(),
            phrases: [
                "ç”¨ \(.applicationName) è¯†å›¾",
                "ç”¨ \(.applicationName) çœ‹çœ‹è¿™æ˜¯ä»€ä¹ˆ",
                "\(.applicationName) å¿«é€Ÿè¯†å›¾",
                "\(.applicationName) æ‹ç…§è¯†åˆ«",
                "\(.applicationName) å¸®æˆ‘è¯†åˆ«çœ¼å‰çš„ä¸œè¥¿"
            ],
            shortTitle: "å¿«é€Ÿè¯†å›¾",
            systemImageName: "eye.circle.fill"
        )
    }
}

// MARK: - Notification Name

extension Notification.Name {
    static let quickVisionTriggered = Notification.Name("quickVisionTriggered")
}

// MARK: - Quick Vision Manager

@MainActor
class QuickVisionManager: ObservableObject {
    static let shared = QuickVisionManager()

    @Published var isProcessing = false
    @Published var lastResult: String?
    @Published var errorMessage: String?

    // å…¬å¼€ streamViewModel ç”¨äº Intent æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€
    private(set) var streamViewModel: StreamSessionViewModel?
    private let tts = TTSService.shared

    private init() {
        // ç›‘å¬ Intent è§¦å‘
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleQuickVisionTrigger(_:)),
            name: .quickVisionTriggered,
            object: nil
        )
    }

    /// è®¾ç½® StreamSessionViewModel å¼•ç”¨
    func setStreamViewModel(_ viewModel: StreamSessionViewModel) {
        self.streamViewModel = viewModel
    }

    @objc private func handleQuickVisionTrigger(_ notification: Notification) {
        let customPrompt = notification.userInfo?["customPrompt"] as? String
        Task { @MainActor in
            // ä»å¿«æ·æŒ‡ä»¤è§¦å‘æ—¶ï¼Œå®Œæˆåè‡ªåŠ¨åœæ­¢æµ
            await performQuickVisionFromIntent(customPrompt: customPrompt)
        }
    }

    /// æ‰§è¡Œå¿«é€Ÿè¯†å›¾
    /// æµç¨‹ï¼šå¯åŠ¨æµ -> æ‹ç…§ -> åœæ­¢æµ -> è¯†å›¾ -> TTSæ’­æŠ¥
    func performQuickVision(customPrompt: String? = nil) async {
        guard !isProcessing else {
            print("âš ï¸ [QuickVision] Already processing")
            return
        }

        guard let streamViewModel = streamViewModel else {
            print("âŒ [QuickVision] StreamViewModel not set")
            tts.speak("è¯†å›¾åŠŸèƒ½æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆæ‰“å¼€åº”ç”¨")
            return
        }

        isProcessing = true
        errorMessage = nil
        lastResult = nil

        // è·å– API Keyï¼ˆåé¢ TTS ä¹Ÿè¦ç”¨ï¼‰
        guard let apiKey = APIKeyManager.shared.getAPIKey(), !apiKey.isEmpty else {
            errorMessage = "è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key"
            tts.speak("è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key")
            isProcessing = false
            return
        }

        // æ’­æŠ¥å¼€å§‹
        tts.speak("æ­£åœ¨è¯†åˆ«", apiKey: apiKey)

        do {
            // 0. æ£€æŸ¥è®¾å¤‡æ˜¯å¦å·²è¿æ¥
            if !streamViewModel.hasActiveDevice {
                print("âŒ [QuickVision] No active device connected")
                throw QuickVisionError.noDevice
            }

            // 1. å¯åŠ¨è§†é¢‘æµï¼ˆå¦‚æœæœªå¯åŠ¨ï¼‰
            if streamViewModel.streamingStatus != .streaming {
                print("ğŸ“¹ [QuickVision] Starting stream...")
                await streamViewModel.handleStartStreaming()

                // ç­‰å¾…æµè¿›å…¥ streaming çŠ¶æ€ï¼ˆæœ€å¤š 5 ç§’ï¼‰
                var streamWait = 0
                while streamViewModel.streamingStatus != .streaming && streamWait < 50 {
                    try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
                    streamWait += 1
                }

                if streamViewModel.streamingStatus != .streaming {
                    print("âŒ [QuickVision] Failed to start streaming")
                    throw QuickVisionError.streamNotReady
                }
            }

            // 2. ç­‰å¾…æµç¨³å®š
            try await Task.sleep(nanoseconds: 500_000_000) // 0.5ç§’

            // 3. æ¸…é™¤ä¹‹å‰çš„ç…§ç‰‡ï¼Œç„¶åæ‹ç…§
            streamViewModel.dismissPhotoPreview()
            print("ğŸ“¸ [QuickVision] Capturing photo...")
            streamViewModel.capturePhoto()

            // 4. ç­‰å¾…ç…§ç‰‡æ•è·å®Œæˆï¼ˆæœ€å¤š 3 ç§’ï¼‰
            var photoWait = 0
            while streamViewModel.capturedPhoto == nil && photoWait < 30 {
                try await Task.sleep(nanoseconds: 100_000_000) // 0.1ç§’
                photoWait += 1
            }

            // å¦‚æœ SDK capturePhoto å¤±è´¥ï¼Œä½¿ç”¨å½“å‰è§†é¢‘å¸§ä½œä¸ºå¤‡é€‰
            let photo: UIImage
            if let capturedPhoto = streamViewModel.capturedPhoto {
                photo = capturedPhoto
                print("ğŸ“¸ [QuickVision] Using SDK captured photo")
            } else if let videoFrame = streamViewModel.currentVideoFrame {
                photo = videoFrame
                print("ğŸ“¸ [QuickVision] SDK capturePhoto failed, using video frame as fallback")
            } else {
                print("âŒ [QuickVision] No photo or video frame available")
                throw QuickVisionError.frameTimeout
            }

            print("ğŸ“¸ [QuickVision] Photo captured: \(photo.size.width)x\(photo.size.height)")

            // 5. é¢„é…ç½® TTS éŸ³é¢‘ä¼šè¯ï¼ˆåœ¨åœæ­¢æµä¹‹å‰ï¼Œé¿å…ä¼šè¯å†²çªï¼‰
            tts.prepareAudioSession()

            // 6. ç«‹å³åœæ­¢è§†é¢‘æµï¼ˆä¸å†éœ€è¦ï¼‰
            print("ğŸ›‘ [QuickVision] Stopping stream after capture")
            await streamViewModel.stopSession()

            // 7. è°ƒç”¨è¯†å›¾ APIï¼ˆä½¿ç”¨å¼€å¤´è·å–çš„ apiKeyï¼‰
            let service = QuickVisionService(apiKey: apiKey)
            let result = try await service.analyzeImage(photo, customPrompt: customPrompt)

            // 8. ä¿å­˜ç»“æœ
            lastResult = result

            // 9. TTS æ’­æŠ¥ç»“æœ
            tts.speak(result, apiKey: apiKey)

            print("âœ… [QuickVision] Complete: \(result)")

        } catch let error as QuickVisionError {
            errorMessage = error.localizedDescription
            print("âŒ [QuickVision] QuickVisionError: \(error)")
            tts.speak(error.localizedDescription, apiKey: apiKey)
            // å‡ºé”™ä¹Ÿè¦åœæ­¢æµ
            await streamViewModel.stopSession()
        } catch {
            errorMessage = error.localizedDescription
            print("âŒ [QuickVision] Error: \(error)")
            tts.speak("è¯†åˆ«å¤±è´¥ï¼Œ\(error.localizedDescription)", apiKey: apiKey)
            // å‡ºé”™ä¹Ÿè¦åœæ­¢æµ
            await streamViewModel.stopSession()
        }

        isProcessing = false
    }

    /// æ‰§è¡Œå¿«é€Ÿè¯†å›¾ï¼ˆä»å¿«æ·æŒ‡ä»¤/Siri è§¦å‘ï¼‰
    /// ä¸ performQuickVision ç›¸åŒï¼Œæµå·²åœ¨è¯†åˆ«å®Œæˆååœæ­¢
    func performQuickVisionFromIntent(customPrompt: String? = nil) async {
        await performQuickVision(customPrompt: customPrompt)
    }

    /// åœæ­¢è§†é¢‘æµï¼ˆåœ¨é¡µé¢å…³é—­æ—¶è°ƒç”¨ï¼‰
    func stopStream() async {
        await streamViewModel?.stopSession()
    }

    /// æ‰‹åŠ¨è§¦å‘å¿«é€Ÿè¯†å›¾ï¼ˆä» UI è°ƒç”¨ï¼‰
    func triggerQuickVision(customPrompt: String? = nil) {
        Task { @MainActor in
            await performQuickVision(customPrompt: customPrompt)
        }
    }
}
